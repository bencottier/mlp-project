{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "import os\n",
    "import ast\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_template = '/Users/ff/results_20200303/slurm-{0}.out'\n",
    "target_template = '/Users/ff/dev/mathematics_dataset-v1.0/{0}-split'\n",
    "\n",
    "jobids = ['extrapolate','interpolate']\n",
    "targetids = jobids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/Users/ff/dev/mlp-project/scripts/data.pickle', 'rb') as f:\n",
    "#    lengths_stats = pickle.load(f)\n",
    "lengths_stats = None\n",
    "\n",
    "if lengths_stats:\n",
    "    print(lengths_stats.keys())\n",
    "\n",
    "extr_tasks = {\n",
    "    'algebra__polynomial_roots_big_src_test.txt':'algebra__polynomial_roots.txt',\n",
    "    'arithmetic__add_or_sub_big_src_test.txt':'arithmetic__add_or_sub.txt',\n",
    "    'arithmetic__add_sub_multiple_longer_src_test.txt':'arithmetic__add_sub_multiple.txt',\n",
    "    'arithmetic__div_big_src_test.txt':'arithmetic__div.txt',\n",
    "    'arithmetic__mixed_longer_src_test.txt':'arithmetic__mixed.txt',\n",
    "    'arithmetic__mul_big_src_test.txt':'arithmetic__mul.txt',\n",
    "    'arithmetic__mul_div_multiple_longer_src_test.txt':'arithmetic__mul_div_multiple.txt',\n",
    "    'comparison__closest_more_src_test.txt':'comparison__closest.txt',\n",
    "    'comparison__kth_biggest_more_src_test.txt':'comparison__kth_biggest.txt',\n",
    "    'comparison__sort_more_src_test.txt':'comparison__sort.txt',\n",
    "    'measurement__conversion_src_test.txt':'measurement__conversion.txt',\n",
    "    'numbers__place_value_big_src_test.txt':'numbers__place_value.txt',\n",
    "    'numbers__round_number_big_src_test.txt':'numbers__round_number.txt',\n",
    "    'probability__swr_p_level_set_more_samples_src_test.txt':'probability__swr_p_level_set.txt',\n",
    "    'probability__swr_p_sequence_more_samples_src_test.txt':'probability__swr_p_sequence.txt'\n",
    "}\n",
    "\n",
    "inter_tasks = {\n",
    "    'algebra__polynomial_roots_src_test.txt':'algebra__polynomial_roots.txt',\n",
    "    'arithmetic__add_or_sub_src_test.txt':'arithmetic__add_or_sub.txt',\n",
    "    'arithmetic__add_sub_multiple_src_test.txt':'arithmetic__add_sub_multiple.txt',\n",
    "    'arithmetic__div_src_test.txt':'arithmetic__div.txt',\n",
    "    'arithmetic__mixed_src_test.txt':'arithmetic__mixed.txt',\n",
    "    'arithmetic__mul_div_multiple_src_test.txt':'arithmetic__mul_div_multiple.txt',\n",
    "    'arithmetic__mul_src_test.txt':'arithmetic__mul.txt',\n",
    "    'comparison__closest_src_test.txt':'comparison__closest.txt',\n",
    "    'comparison__kth_biggest_src_test.txt':'comparison__kth_biggest.txt',\n",
    "    'comparison__sort_src_test.txt':'comparison__sort.txt',\n",
    "    'measurement__conversion_src_test.txt':'measurement__conversion.txt',\n",
    "    'numbers__place_value_src_test.txt':'numbers__place_value.txt',\n",
    "    'numbers__round_number_src_test.txt':'numbers__round_number.txt',\n",
    "    'probability__swr_p_level_set_src_test.txt':'probability__swr_p_level_set.txt',\n",
    "    'probability__swr_p_sequence_src_test.txt':'probability__swr_p_sequence.txt'\n",
    "}\n",
    "\n",
    "train_names = {'extrapolate':extr_tasks,\n",
    "               'interpolate':inter_tasks}\n",
    "\n",
    "#print(train_names['extrapolate']['algebra__polynomial_roots_big_src_test.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(lines, regex, end=False):\n",
    "    #Â we have these lines\n",
    "    # filename\n",
    "    # [2020-03-03 09:16:02,784 INFO] Translating shard 0.\n",
    "    # <filename>.txt\n",
    "    # ....\n",
    "    # PRED AVG SCORE:\n",
    "    files = []\n",
    "    for i,line in enumerate(lines):\n",
    "        match = re.findall(regex, line)\n",
    "        if match:\n",
    "            if end:\n",
    "                filename = lines[i].strip()            \n",
    "                files.append((filename, i))\n",
    "            else:\n",
    "                filename = lines[i].strip()\n",
    "                files.append((filename, i))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_files(raw_lines, filenames_info):\n",
    "    files = {}\n",
    "    for i,f in enumerate(filenames_info):\n",
    "        print(f[0])\n",
    "        filename = f[0]\n",
    "        start_line = f[1]\n",
    "        end_line = f[3]\n",
    "        \n",
    "        file_ = raw_lines[start_line:end_line]\n",
    "        files[i] = (file_)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Result:\n",
    "    def __init__(self, string, prediction, prob, target):\n",
    "        self.string = string\n",
    "        self.prediction = prediction\n",
    "        self.prob = prob\n",
    "        self.target = target\n",
    "    \n",
    "    def __str__(self):\n",
    "        return (f'String: {self.string}\\n\\\n",
    "                 Target: {self.target}\\n\\\n",
    "                 Prediction: {self.prediction}\\n\\\n",
    "                 Likelihood: {self.prob}')\n",
    "    \n",
    "def parse_single_result(string, pred, prob, target):\n",
    "    string_ = re.sub(r'SENT [0-9]*:\\ ', '', string)\n",
    "    string_ = ast.literal_eval(string_)\n",
    "    string = \"\".join(str(x) for x in string_).replace('_',' ')\n",
    "    \n",
    "    pred_ = re.sub(r'PRED [0-9]*:\\ ', '', pred)\n",
    "    pred = \"\".join(str(x) for x in pred_).strip().replace('_',' ')\n",
    "    \n",
    "    prob_ = re.sub(r'PRED SCORE:\\ ', '', prob)\n",
    "    prob = float(prob_)\n",
    "    \n",
    "    return Result(string, pred, prob, target)\n",
    "    \n",
    "def parse_file_results(raw_lines, targets):\n",
    "    filename = raw_lines[0].strip()\n",
    "    _ = raw_lines[1]\n",
    "    res = [line for line in raw_lines[2:] if line != '\\n']\n",
    "    \n",
    "    if len(res) % 3 != 0:\n",
    "        print('Error', filename)\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    for i in range(0, len(res), 3):\n",
    "        string = res[i]\n",
    "        prediction = res[i+1]\n",
    "        prob = res[i+2]\n",
    "        target = targets[i//3]\n",
    "        results.append(parse_single_result(string, prediction, prob, target))\n",
    "    return filename, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_targets(tasks, targetid):\n",
    "    targets = {}\n",
    "    for key in sorted(tasks.keys()):\n",
    "        task_name = tasks[key][0].strip()\n",
    "        task_name = task_name.replace('_src_test.txt','')\n",
    "        path = os.path.join(target_template.format(targetid), task_name+'_tgt_test.txt')\n",
    "        with open(path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [l.strip().replace('_',' ').replace('\\n','') for l in lines]\n",
    "        targets[key] = lines\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ff/results_20200303/slurm-extrapolate.out\n",
      "algebra__polynomial_roots_big_src_test.txt\n",
      "arithmetic__add_or_sub_big_src_test.txt\n",
      "arithmetic__add_sub_multiple_longer_src_test.txt\n",
      "arithmetic__div_big_src_test.txt\n",
      "arithmetic__mixed_longer_src_test.txt\n",
      "arithmetic__mul_big_src_test.txt\n",
      "arithmetic__mul_div_multiple_longer_src_test.txt\n",
      "comparison__closest_more_src_test.txt\n",
      "comparison__kth_biggest_more_src_test.txt\n",
      "comparison__sort_more_src_test.txt\n",
      "measurement__conversion_src_test.txt\n",
      "numbers__place_value_big_src_test.txt\n",
      "numbers__round_number_big_src_test.txt\n",
      "probability__swr_p_level_set_more_samples_src_test.txt\n",
      "probability__swr_p_sequence_more_samples_src_test.txt\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: <_ast.Attribute object at 0x12accb1d0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-4290192fc10a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjobid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtask_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_file_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjobid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-463e4678f76f>\u001b[0m in \u001b[0;36mparse_file_results\u001b[0;34m(raw_lines, targets)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_single_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-463e4678f76f>\u001b[0m in \u001b[0;36mparse_single_result\u001b[0;34m(string, pred, prob, target)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_single_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstring_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'SENT [0-9]*:\\ '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mstring_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/lib/python3.7/ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/lib/python3.7/ast.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/lib/python3.7/ast.py\u001b[0m in \u001b[0;36m_convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/lib/python3.7/ast.py\u001b[0m in \u001b[0;36m_convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'malformed node or string: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnaryOp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUAdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUSub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: <_ast.Attribute object at 0x12accb1d0>"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for jobid, targetid in zip(jobids,targetids):\n",
    "    filename = filename_template.format(jobid)\n",
    "    print(filename)\n",
    "    \n",
    "    # Read slurm output\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    files_start = get_files(lines, r'([a-zA-Z]|_)*.txt')\n",
    "    files_end = get_files(lines, r'PRED AVG SCORE: [0-9]*.', end=True)\n",
    "    \n",
    "    # Merge these two lists\n",
    "    merged = sorted([(i[0][0], i[0][1], i[1][0], i[1][1]) for i in zip(files_start,files_end)])\n",
    "    \n",
    "    # Split the lines into the different tasks\n",
    "    tasks = split_files(lines, merged)\n",
    "    targets = extract_targets(tasks, targetid)\n",
    "    \n",
    "    # Create results objects\n",
    "    data[jobid] = {}\n",
    "    for key in sorted(tasks.keys()):\n",
    "        task_name, results = parse_file_results(tasks[key], targets[key])\n",
    "        data[jobid][task_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.keys())\n",
    "print(data['interpolate'].keys())\n",
    "print(data['extrapolate'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "### ACCURACIES\n",
    "################################\n",
    "\n",
    "\n",
    "def compute_bleu_corpus_accuracy(sentences):\n",
    "    hyps = [None] * len(sentences)\n",
    "    refs = [None] * len(sentences)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        hyps[i] = sentence.prediction\n",
    "        refs[i] = sentence.target\n",
    "    corpus_bleu = nltk.translate.bleu_score.corpus_bleu(refs, hyps)\n",
    "    return corpus_bleu\n",
    "\n",
    "def compute_bleu_sentence_accuracy(sentences):\n",
    "    smoothing_function = nltk.translate.bleu_score.SmoothingFunction().method1\n",
    "    results = np.zeros(len(sentences))\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        results[i] = nltk.translate.bleu_score.sentence_bleu(sentence.target, \n",
    "                                                             sentence.prediction, \n",
    "                                                             smoothing_function=smoothing_function)\n",
    "    return results\n",
    "\n",
    "def compute_binary_accuracy(sentences):\n",
    "    results = np.zeros(len(sentences))\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        results[i] = (1 if np.array_equal(sentence.target, sentence.prediction) else 0)\n",
    "    return results\n",
    "\n",
    "def compute_nll(sentences):\n",
    "    results = np.zeros(len(sentences))\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        results[i] = sentence.prob\n",
    "    return results\n",
    "    \n",
    "################################\n",
    "### STATISTICS\n",
    "################################\n",
    "\n",
    "def count_numbers_length(sentences):\n",
    "    float_pattern = \"[+-]?(?:[0-9]*[.])?[0-9]+\"\n",
    "    results = np.zeros(len(sentences))\n",
    "    for i,sentence in enumerate(sentences):\n",
    "        matches = re.findall(float_pattern, sentence.string)\n",
    "        lens = [len(match) for match in matches]\n",
    "        avg_len = sum(lens) / len(lens) if len(lens) > 0 else 0.\n",
    "        results[i] = avg_len\n",
    "    return results\n",
    "\n",
    "def count_number_of_numbers(sentences):\n",
    "    float_pattern = \"[+-]?(?:[0-9]*[.])?[0-9]+\"\n",
    "    results = np.zeros(len(sentences))\n",
    "    for i,sentence in enumerate(sentences):\n",
    "        matches = re.findall(float_pattern, sentence.string)\n",
    "        results[i] = len(matches)\n",
    "    return results\n",
    "\n",
    "def ratio_words_numbers(sentences):\n",
    "    results = np.zeros(len(sentences))\n",
    "    for i,sentence in enumerate(sentences):\n",
    "        numbers = sum(c.isdigit() for c in sentence.string)\n",
    "        words   = sum(c.isalpha() for c in sentence.string)\n",
    "        results[i] = words / numbers if numbers != 0 else 0\n",
    "    return results\n",
    "\n",
    "def len_sentences(sentences):\n",
    "    results = np.zeros(len(sentences))\n",
    "    for i,sentence in enumerate(sentences):\n",
    "        results[i] = len(sentence.string)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_hist(data, n_bins=3, density=False,\n",
    "                      stats_func = [compute_nll, compute_binary_accuracy, compute_bleu_sentence_accuracy],\n",
    "                      stats_titles = ['nll', 'binary', 'bleu_sentence'],\n",
    "                      extra=None):\n",
    "    \n",
    "    if extra: n_cols = len(stats_func) + 1\n",
    "    else: n_cols = len(stats_func)\n",
    "        \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=n_cols,  figsize=(10,3))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    for i,stats in enumerate(stats_func):\n",
    "        if stats_titles[i] == 'binary':\n",
    "            width = 0.35\n",
    "            for bin_ in range(n_bins):\n",
    "                s = stats(data[bin_])\n",
    "                axs[i].bar(bin_ - width/2, s.sum(), width, label='1', color='g')\n",
    "                axs[i].bar(bin_ + width/2, (len(data[bin_]) - s.sum()), width, label='0', color='r')\n",
    "        else:\n",
    "            for bin_ in range(n_bins):\n",
    "                axs[i].hist(stats(data[bin_]), label=bin_, alpha=0.5, density=density)\n",
    "            axs[i].legend()\n",
    "        axs[i].set_title(stats_titles[i])\n",
    "        \n",
    "    if extra:\n",
    "        axs[-1].bar(*zip(*extra.items()))\n",
    "        axs[-1].set_title('train lengths')\n",
    "        #axs[-1].bar(range(len(extra)), list(extra.values()), align='center')\n",
    "        #axs[-1].set_xticklabels(range(len(extra)), list(extra.keys()))\n",
    "        \n",
    "    plt.show()\n",
    "        \n",
    "    #fig, axs = plt.subplots(nrows=1, ncols=1,  figsize=(10,3))\n",
    "    #fig.tight_layout()\n",
    "    #for i in range(n_bins):\n",
    "    #    axs.hist([d.prob for d in data[i]], label=i, alpha=0.5)\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "def compute_statistics(results, function, method='digitize', n_bins=3, density=False,\n",
    "                       stats_func = [compute_nll, compute_binary_accuracy, compute_bleu_sentence_accuracy],\n",
    "                       stats_titles = ['nll', 'binary', 'bleu_sentence'],\n",
    "                       extra=None):\n",
    "    print(function)\n",
    "    stats = function(results)\n",
    "\n",
    "    # Split into bins of fixed width\n",
    "    if method == 'digitize':\n",
    "        bins = np.linspace(stats.min(), stats.max(), n_bins, endpoint=False)\n",
    "        inds = np.digitize(stats, bins)\n",
    "\n",
    "        results_bins = [[] for i in range(n_bins)]\n",
    "        for i,v in enumerate(inds):\n",
    "            results_bins[v-1].append(results[i])\n",
    "\n",
    "    # Split into bins with fixed number of elements\n",
    "    # based on sorted results\n",
    "    elif method == 'equal_split':\n",
    "        sorted_ = np.argsort(stats)\n",
    "        results_bins = []\n",
    "        bins_indices = np.array_split(np.arange(len(results)), n_bins)\n",
    "        for bin_ in range(n_bins):\n",
    "            results_bins.append([])\n",
    "            for i in bins_indices[bin_]:\n",
    "                results_bins[bin_].append(results[sorted_[i]])        \n",
    "    else:\n",
    "        print('WARNING - NO METHOD SELECTED')\n",
    "        return\n",
    "        \n",
    "        \n",
    "    #for i in range(n_bins):\n",
    "    #    t = compute_binary_accuracy(results_bins[i])\n",
    "    #    print(t.mean(), t.std())\n",
    "\n",
    "    #print(len(results_bins), len(results_bins[0]), len(results_bins[1]), len(results_bins[2]))\n",
    "    create_multi_hist(results_bins, n_bins=n_bins, density=density, \n",
    "                      stats_func=stats_func, stats_titles=stats_titles,\n",
    "                      extra=extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_func =  [compute_nll, compute_binary_accuracy]#, compute_bleu_sentence_accuracy]\n",
    "stats_titles =  ['nll', 'binary']#, 'bleu_sentence']\n",
    "\n",
    "for targetid in targetids:\n",
    "    print()\n",
    "    print('***********************')\n",
    "    print(targetid)\n",
    "    print('***********************')\n",
    "    print()\n",
    "    for key in sorted(data[targetid].keys()):\n",
    "        print('-----------------------------------------------')\n",
    "        print(key)\n",
    "        results = data[targetid][key]\n",
    "\n",
    "        task_lengths = {}\n",
    "        if lengths_stats:\n",
    "            for d in ['easy','medium','hard']:\n",
    "                task_lengths[d] = lengths_stats[d][train_names[targetid][key]].mean()\n",
    "                                \n",
    "        number_lengths = count_numbers_length(results)\n",
    "        print('Number lengths: ', number_lengths.mean())\n",
    "\n",
    "        number_of_numbers = count_number_of_numbers(results)\n",
    "        print('Number of numbers: ', number_of_numbers.mean())\n",
    "\n",
    "        words_numbers_ratio = ratio_words_numbers(results)\n",
    "        print('Words/number ratio: ', words_numbers_ratio.mean())\n",
    "\n",
    "        length_sentences = len_sentences(results)\n",
    "        print('Avg. sentence length: ', length_sentences.mean())\n",
    "\n",
    "        dataset = pd.DataFrame({'Number lengths': number_lengths, \n",
    "                                'Number of numbers': number_of_numbers,\n",
    "                                'Words/number ratio': words_numbers_ratio,\n",
    "                                'Avg. sentence length': length_sentences})\n",
    "        \n",
    "        sns.pairplot(dataset)\n",
    "        plt.show()\n",
    "\n",
    "        #binary_acc = compute_binary_accuracy(results)\n",
    "        #print('Binary: ', binary_acc.mean())\n",
    "\n",
    "        #print()\n",
    "        compute_statistics(results, count_numbers_length, method='equal_split', \n",
    "                           stats_func=stats_func, stats_titles=stats_titles)\n",
    "        compute_statistics(results, count_number_of_numbers, method='equal_split', \n",
    "                           stats_func=stats_func, stats_titles=stats_titles)\n",
    "        compute_statistics(results, ratio_words_numbers, method='equal_split', \n",
    "                           stats_func=stats_func, stats_titles=stats_titles)\n",
    "        compute_statistics(results, len_sentences, method='equal_split', \n",
    "                           stats_func=stats_func, stats_titles=stats_titles, extra=task_lengths)\n",
    "\n",
    "\n",
    "        #sentence_acc = compute_bleu_sentence_accuracy(results)\n",
    "        #print('Sentence: ', sentence_acc.mean())\n",
    "\n",
    "        #corpus_acc = compute_bleu_sentence_accuracy(results)\n",
    "        #print('Corpus: ', sentence_acc.mean())\n",
    "\n",
    "        print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('pymlp': venv)",
   "language": "python",
   "name": "python37064bitpymlpvenv7daaa6461aa04f2d9982f552caaf5e61"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
